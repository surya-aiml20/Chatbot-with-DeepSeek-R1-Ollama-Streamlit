# Chatbot-with-DeepSeek-R1-Ollama-Streamlit
Local LLM App using DeepSeek-R1-Distill-Qwen-1.5B

This mini project demonstrates how to run the DeepSeek-R1-Distill-Qwen-1.5B model locally using Ollama and build an interactive web interface with Streamlit, integrating LangChain to enhance prompt handling and LLM interaction.

ğŸš€ Features
ğŸ§  Runs DeepSeek-R1-Distill-Qwen-1.5B model locally via ollama

ğŸŒ Simple and interactive Streamlit web app

ğŸ› ï¸ Integrated with LangChain for prompt management and flexibility

ğŸ”’ Completely private & offline â€“ no cloud API usage

ğŸ“¦ Tech Stack
Ollama â€” to pull and run LLM models locally

Streamlit â€” for frontend UI

LangChain â€” to interact with the LLM

Python 3.9+ â€” base language

