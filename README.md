# Chatbot-with-DeepSeek-R1-Ollama-Streamlit
Local LLM App using DeepSeek-R1-Distill-Qwen-1.5B

This mini project demonstrates how to run the DeepSeek-R1-Distill-Qwen-1.5B model locally using Ollama and build an interactive web interface with Streamlit, integrating LangChain to enhance prompt handling and LLM interaction.

🚀 Features
🧠 Runs DeepSeek-R1-Distill-Qwen-1.5B model locally via ollama

🌐 Simple and interactive Streamlit web app

🛠️ Integrated with LangChain for prompt management and flexibility

🔒 Completely private & offline – no cloud API usage

📦 Tech Stack
Ollama — to pull and run LLM models locally

Streamlit — for frontend UI

LangChain — to interact with the LLM

Python 3.9+ — base language

